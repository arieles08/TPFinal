---
title: "Trabajo Práctico Nº1: Regresión lineal"
author: "Renso Gil y Leandro Morinigo"
date: "14/10/2022"
output:
  html_document:
    toc: yes
    toc_float: yes
    df_print: paged
    theme: united
editor_options: 
  markdown: 
    wrap: 72
---
## Carga de librerías y datasets
### Librerías a utiliza
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```
Se cargan las librerías necesarias para el trabajo práctico.
###Librerias
```{r}

library(tidyverse)
library(tidymodels)
library(rsample)
library(ggplot2)
library(GGally)
library(DALEX)
library(randomForest)
library(iBreakDown)
```


### Cargar archivo
```{r}
datos_properati <- read.csv("properati_preprocesado_2022.csv")
# creamos nueva variable de superficie descubierta

datos_properati = datos_properati %>%
  mutate(surface_uncovered = surface_total - surface_covered)

glimpse(datos_properati)

```

## Correlación entre variables
```{r}
# graficamos con ggpairs coloreando por property type
g <- ggpairs(datos_properati %>% select(-c(id,l3)), aes(color = property_type), 
          upper = list(continuous = wrap("cor", size = 3, hjust=0.5)), legend = 25, progress=FALSE) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "bottom") + 
  theme_bw()
# hacemos un loop para cambiar los colores del gráfico
for(i in 1:g$nrow) {
  for(j in 1:g$ncol){
    g[i,j] <- g[i,j] + 
      scale_fill_brewer(palette="Dark2") +  
      scale_color_brewer(palette="Dark2")
        }
}
g 
```

### Particionar el dataset en entrenamiento y test

```{r}
# fijamos semilla
set.seed(22)
# Partición Train y Test, indicando proporción
train_test <- initial_split(datos_properati, prop = 0.75)
train_data <- training(train_test)
test_data <- testing(train_test)
# vemos las dimensiones de cada partición
train_data %>%
  dim_desc() 
```
#### Nuevas variables

Variables creadas a partir de los metros cuadradas por barrio
```{r}
# Creamos una nueva variable  de precios por metro cuadrado
train_data = train_data %>% 
  mutate(pxm2 = round(price/surface_total,0))
# Armamos un dataframe que muestre los promedios de pxm2 en cada barrio
AVG_pxm2_l3 = train_data %>% 
  group_by(l3) %>%
  summarise(AVG_pxm2_l3 = mean(pxm2))
AVG_pxm2_l3
```

Distribución del precio promedio por m2
```{r}
# boxplot de precios por metro cuadrado
ggplot(data = AVG_pxm2_l3, aes(x = AVG_pxm2_l3)) + 
  geom_boxplot(alpha = 0.75, fill="firebrick") +
  labs(title = "Boxplot de precios promedio de barrios por m2") +
  labs(x = "Precios promedio de barrios por m2") +
  theme_bw()
```
Aplicaremos el siguiente criterio para agrupar los barrios en:

* precio_bajo: barrios cuyo precio promedio por m2 sea menor al Q1
* precio_medio: barrios cuyo precio promedio se encuentre en el RI
* precio_alto: barrios cuyo precio promedio por m2 sea mayor al Q3

```{r}
# armamos nueva variable siguiendo tales criterios
AVG_pxm2_l3 = AVG_pxm2_l3 %>%
  mutate(tipo_barrio = case_when(
    AVG_pxm2_l3 < quantile(AVG_pxm2_l3)[2] ~ "precio_bajo",
    AVG_pxm2_l3 >= quantile(AVG_pxm2_l3)[2] & AVG_pxm2_l3 < quantile(AVG_pxm2_l3)[4] ~ "precio_medio",
    TRUE ~ "precio_alto"
                                 )
         )
write.csv(AVG_pxm2_l3, 'AVG_pxm2_l3.csv')

# unimos esta clasificación al dataset original
train_data = train_data %>% left_join(AVG_pxm2_l3[c("l3","tipo_barrio","AVG_pxm2_l3")], by = 'l3') 
test_data = test_data %>% left_join(AVG_pxm2_l3[c("l3","tipo_barrio", "AVG_pxm2_l3")], by = 'l3') 
head(train_data)


```

```{r}
head(test_data)
```

```{r}
head(AVG_pxm2_l3)
```




### Modelo de regresión multiple

$E(precio)=\beta_0+\beta_1surface\_covered+\beta_2tipo\_barrio$

```{r}
# Modelo multiple
# Modelo varias + barrios
modelo_varias <- lm(price ~ surface_covered + surface_uncovered + rooms + bathrooms + property_type + l3, data = train_data)
tidy_varias <- tidy(modelo_varias, conf.int = TRUE)
tidy_varias
```

#### Significado de los coeficientes estimados 

* $\hat{\beta_o}$ : (categoría basal de la variable categórica): es la media del precio para las casas de abasto sin superficie, sin baño y sin habitaciones
* $\hat{\beta_{surface\_covered}}$ : es la pendiente de incremento de precio por superficie para cada tipo de barrio y tipo de propiedad
* $\hat{\beta_{surface\_uncovered}}$ : es la pendiente de incremento de precio por superficie descubierta para cada tipo de barrio y tipo de propiedad
* $\hat{\beta_{tipo\_barrioprecio\_bajo}}$ : es la diferencia en los niveles medios de precios de los barrios de precio bajos  respecto de los barrios de precio alto (categoría basal)
* $\hat{\beta_{tipo\_barrioprecio\_medio}}$ : es la diferencia en los niveles medios de precios de los barrios de precio medios  respecto de los barrios de precio alto (categoría basal)

#### Significatividad individual

Test para las $\beta_k$
Se pretende probar si el coeficiente de regresón de la variable es distinto de cero. 

Hipótesis:

* $H_0:\beta_k = 0$
* $H_1:\beta_k ≠ 0$

```{r}
options("scipen"=1)
tidy_varias %>%
  select(term, statistic, p.value, conf.low, conf.high)
```
Se grafica los coeficientes estimados y sus intervalos de confianza.
```{r}
# Gráfico de los Coeficientes
ggplot(tidy_varias, aes(estimate, term, color=p.value < 0.05, xmin = conf.low, xmax = conf.high, height = 0)) +
  geom_point() +
  geom_vline(xintercept = 0, lty = 4, color = "black") +
  geom_errorbarh() +
  scale_color_manual(values=c('firebrick', 'forestgreen')) +
  guides(color="none") +
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```

#### Test F : evaluar significatividad global

Hipótesis:

* $H_0: β_1 = β_2 = · · · = β_{p−1} = 0$

* $H_1:$ no todos los $β_k$ ($k = 1, 2,..., p−1$) son iguales a 0. 

```{r}
glance(modelo_varias)
```

```{r}
summary(modelo_varias)
```

### Evaluación del modelo

```{r}
# Agregamos la predicciones al dataset de testeo
pred_varias = augment(modelo_varias, newdata = test_data) 
pred_varias %>% select(l3,rooms, surface_covered, surface_uncovered, property_type, .fitted, .resid)
```

```{r}
rmse(data = pred_varias, truth = price, estimate = .fitted)
```

```{r}
# Listado de modelos
modelos_lineales = list(modelo_lineal_basico = modelo_varias)

# Realizamos predicciones en test
lista_predicciones_testing = map(.x = modelos_lineales, .f = augment, newdata = test_data) 

# Obtenemos las métricas de performance en test
performance_modelos_lineales_test <- map_dfr(.x = lista_predicciones_testing, .f = metrics, truth = price, estimate = .fitted, .id="modelo") %>%
                                              filter(.metric!="rsq") %>% 
                                              arrange(.metric, modelo) %>% 
                                              mutate(.estimate= round(.estimate, digits = 2))
performance_modelos_lineales_test
```



### Aplicación de Random Forest

```{r}
modelo_randomForest <- randomForest(price ~ surface_covered + surface_uncovered + rooms + bathrooms + property_type + l3, data = train_data)
```

```{r}
variables_train <- train_data %>% select(-price)
variables_test <- test_data %>% select(-price)
```

```{r}
precio_train <- train_data %>% select(price) %>% as.matrix()
precio_test <- test_data %>% select(price) %>% as.matrix() 
```



```{r}
# Agregamos la predicciones al dataset de testeo
pred_randomForest = predict(modelo_randomForest, variables_test)

```

```{r}
# Función augment para RF
augment_RF <- function(modelo_red, matriz_variables, variable_target) {
  y_pred <- predict(modelo_red, matriz_variables, verbose=0) %>% as.vector()
  df_predicciones <- tibble(y = as.vector(variable_target), y_pred = y_pred) %>% 
                      mutate(residuo=y-y_pred)
  return(df_predicciones)
}
```


```{r}
performance_RF<-augment_RF(modelo_randomForest, variables_test, precio_test) %>%
  metrics(truth = y, estimate = y_pred) %>% 
  filter(.metric!="rsq") %>% 
  arrange(.metric) %>% 
  mutate(.estimate= round(.estimate, digits = 2))
performance_RF
```

### Break down

```{r}
explain_rf <- DALEX::explain(model = modelo_randomForest,  
                        data = variables_train,
                           y = precio_train, 
                       label = "Random Forest")
```

###Predict_parts

```{r}
bd_rf <- predict_parts(explainer = explain_rf,
                 new_observation = variables_test,
                            type = "break_down")
bd_rf 
```

```{r}
plot(bd_rf)
```

